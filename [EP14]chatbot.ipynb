{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[EP14]트랜스포머로 만드는 대화형 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<<목차>>\n",
    "\n",
    "\n",
    "1) 데이터 수집하기\n",
    "\n",
    "2) 데이터 전처리하기\n",
    "\n",
    "3) SubwordTextEncoder 사용하기\n",
    "\n",
    "4) 모델 구성하기\n",
    "\n",
    "5) 모델 평가하기\n",
    "\n",
    "6) 루브릭\n",
    "\n",
    "7) 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.\n",
    "\n",
    "이 데이터는 아래의 링크에서 다운로드할 수 있습니다.\n",
    "\n",
    "songys/Chatbot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = '/home/june/Github/Exploration/data/ep14/ChatbotData.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = len(data)\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12시 땡!'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문(Q)\n",
    "data['Q'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하루가 또 가네요.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 답변(A)\n",
    "data['A'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5290\n",
       "1    3570\n",
       "2    2963\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 감정(label): 중립 0, 부정 1, 긍정 2 레이블링\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^가-힣?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "  inputs, outputs = [], []\n",
    "  for i in range(MAX_SAMPLES):\n",
    "    # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "    inputs.append(preprocess_sentence(data['Q'].values[i]))\n",
    "    outputs.append(preprocess_sentence(data['A'].values[i]))\n",
    "\n",
    "  return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8127]\n",
      "END_TOKEN의 번호 : [8128]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8129\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5742, 612, 2481, 4148]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2352, 7481, 7, 6245, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8129\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 30000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 512)    7318016     ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 512)    9421312     ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8129)   4170177     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,909,505\n",
      "Trainable params: 20,909,505\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 16 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.3 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.6, beta_2=0.99, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "370/370 [==============================] - 19s 40ms/step - loss: 1.2435 - accuracy: 0.0373\n",
      "Epoch 2/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.9917 - accuracy: 0.0509\n",
      "Epoch 3/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.9187 - accuracy: 0.0549\n",
      "Epoch 4/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.8497 - accuracy: 0.0588\n",
      "Epoch 5/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.7665 - accuracy: 0.0647\n",
      "Epoch 6/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.6726 - accuracy: 0.0730\n",
      "Epoch 7/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.5756 - accuracy: 0.0829\n",
      "Epoch 8/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.4891 - accuracy: 0.0926\n",
      "Epoch 9/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.4176 - accuracy: 0.1012\n",
      "Epoch 10/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.3597 - accuracy: 0.1090\n",
      "Epoch 11/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.3132 - accuracy: 0.1153\n",
      "Epoch 12/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.2649 - accuracy: 0.1223\n",
      "Epoch 13/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.2197 - accuracy: 0.1296\n",
      "Epoch 14/20\n",
      "370/370 [==============================] - 14s 39ms/step - loss: 0.1839 - accuracy: 0.1352\n",
      "Epoch 15/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.1547 - accuracy: 0.1401\n",
      "Epoch 16/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.1318 - accuracy: 0.1443\n",
      "Epoch 17/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.1127 - accuracy: 0.1479\n",
      "Epoch 18/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0992 - accuracy: 0.1505\n",
      "Epoch 19/20\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0850 - accuracy: 0.1536\n",
      "Epoch 20/20\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0745 - accuracy: 0.1561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85ac05dfa0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_question_list = [\n",
    "    \"안녕 오랜만이야\",\n",
    "    \"잘 지냈어?\",\n",
    "    \"뭐 먹을까\",\n",
    "    \"메뉴 추천해줘\",\n",
    "    \"어제 뭐 먹었어?\",\n",
    "    \"나랑 놀자\",\n",
    "    \"어디 가고 싶어?\",\n",
    "    \"널 만나서 기뻐\",\n",
    "    \"웃어줄래\",\n",
    "    \"삶은 뭘까?\",\n",
    "    \"인생살이 왜이리 힘드냐\",\n",
    "    \"이제 그만 쉬고 싶어\",\n",
    "    \"너무 고독하다\",\n",
    "    \"죽으면 어떻게 될까\",\n",
    "    \"내가 죽으면 슬퍼해 줄거야?\",\n",
    "    \"도망가고 싶다\",\n",
    "    \"우리 마지막이야\",\n",
    "    \"나 간다 잘 지내 안녕\",\n",
    "    \"넌 최고였어\",\n",
    "    \"나 잊지마\",\n",
    "    \"나는 심장이 없어\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_answers(input_question_list):\n",
    "    for input_qusetion in input_question_list:\n",
    "        sentence_generation(input_qusetion)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕 오랜만이야\n",
      "출력 : 여행을 떠나세요 .\n",
      "\n",
      "입력 : 잘 지냈어?\n",
      "출력 : 안부를 물어주시다니 감사합니다 .\n",
      "\n",
      "입력 : 뭐 먹을까\n",
      "출력 : 좀 먹어도 괜찮아요 .\n",
      "\n",
      "입력 : 메뉴 추천해줘\n",
      "출력 : 누구랑 먹는 냐에 따라 다르겠죠 .\n",
      "\n",
      "입력 : 어제 뭐 먹었어?\n",
      "출력 : 저는 배터리가 밥이예요 .\n",
      "\n",
      "입력 : 나랑 놀자\n",
      "출력 : 지금 그러고 있어요 .\n",
      "\n",
      "입력 : 어디 가고 싶어?\n",
      "출력 : 오래 쓰셨나봐요 .\n",
      "\n",
      "입력 : 널 만나서 기뻐\n",
      "출력 : 자신하고 만나는 시간도 중요해요 .\n",
      "\n",
      "입력 : 웃어줄래\n",
      "출력 : 기대를 버려야 덜 다칠 거예요 .\n",
      "\n",
      "입력 : 삶은 뭘까?\n",
      "출력 : 고민하고 있다면 그게 맞을 거예요 .\n",
      "\n",
      "입력 : 인생살이 왜이리 힘드냐\n",
      "출력 : 같이 운동하자고 해도 괜찮을 거 같아요 .\n",
      "\n",
      "입력 : 이제 그만 쉬고 싶어\n",
      "출력 : 아무 생각 하지 말고 쉬세요 .\n",
      "\n",
      "입력 : 너무 고독하다\n",
      "출력 : 혼자가 아니에요 .\n",
      "\n",
      "입력 : 죽으면 어떻게 될까\n",
      "출력 : 너무 자책하지 마세요 .\n",
      "\n",
      "입력 : 내가 죽으면 슬퍼해 줄거야?\n",
      "출력 : 행복하게 살아요 .\n",
      "\n",
      "입력 : 도망가고 싶다\n",
      "출력 : 가끔은 이기적이어도 괜찮아요 .\n",
      "\n",
      "입력 : 우리 마지막이야\n",
      "출력 : 바쁘거나 마음이 없을 거예요 .\n",
      "\n",
      "입력 : 나 간다 잘 지내 안녕\n",
      "출력 : 잘 다녀이야기 .\n",
      "\n",
      "입력 : 넌 최고였어\n",
      "출력 : 제가 놀아드리고 싶네요 .\n",
      "\n",
      "입력 : 나 잊지마\n",
      "출력 : 때론 잊어버리는 것이 좋을 때도 있어요 .\n",
      "\n",
      "입력 : 나는 심장이 없어\n",
      "출력 : 계속 이야기 하면 사귀자는 거 돌려 말하는 걸 수도 있어요 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 20에폭\n",
    "\n",
    "print_answers(input_question_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0664 - accuracy: 0.1578\n",
      "Epoch 2/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0583 - accuracy: 0.1599\n",
      "Epoch 3/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0540 - accuracy: 0.1610\n",
      "Epoch 4/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0481 - accuracy: 0.1623\n",
      "Epoch 5/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0446 - accuracy: 0.1633\n",
      "Epoch 6/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0404 - accuracy: 0.1643\n",
      "Epoch 7/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0377 - accuracy: 0.1651\n",
      "Epoch 8/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0353 - accuracy: 0.1657\n",
      "Epoch 9/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0321 - accuracy: 0.1665\n",
      "Epoch 10/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0304 - accuracy: 0.1670\n",
      "Epoch 11/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0288 - accuracy: 0.1675\n",
      "Epoch 12/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0279 - accuracy: 0.1676\n",
      "Epoch 13/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0259 - accuracy: 0.1680\n",
      "Epoch 14/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0243 - accuracy: 0.1686\n",
      "Epoch 15/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0228 - accuracy: 0.1689\n",
      "Epoch 16/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0220 - accuracy: 0.1692\n",
      "Epoch 17/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0205 - accuracy: 0.1695\n",
      "Epoch 18/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0203 - accuracy: 0.1697\n",
      "Epoch 19/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0190 - accuracy: 0.1701\n",
      "Epoch 20/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0180 - accuracy: 0.1701\n",
      "Epoch 21/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0174 - accuracy: 0.1704\n",
      "Epoch 22/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0167 - accuracy: 0.1706\n",
      "Epoch 23/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0166 - accuracy: 0.1707\n",
      "Epoch 24/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0153 - accuracy: 0.1710\n",
      "Epoch 25/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0154 - accuracy: 0.1709\n",
      "Epoch 26/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0144 - accuracy: 0.1712\n",
      "Epoch 27/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0140 - accuracy: 0.1713\n",
      "Epoch 28/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0144 - accuracy: 0.1712\n",
      "Epoch 29/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0137 - accuracy: 0.1714\n",
      "Epoch 30/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0129 - accuracy: 0.1716\n",
      "Epoch 31/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0123 - accuracy: 0.1718\n",
      "Epoch 32/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0120 - accuracy: 0.1717\n",
      "Epoch 33/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0115 - accuracy: 0.1719\n",
      "Epoch 34/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0113 - accuracy: 0.1720\n",
      "Epoch 35/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0109 - accuracy: 0.1722\n",
      "Epoch 36/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0106 - accuracy: 0.1722\n",
      "Epoch 37/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0108 - accuracy: 0.1721\n",
      "Epoch 38/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0103 - accuracy: 0.1724\n",
      "Epoch 39/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0100 - accuracy: 0.1723\n",
      "Epoch 40/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0098 - accuracy: 0.1724\n",
      "Epoch 41/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0096 - accuracy: 0.1725\n",
      "Epoch 42/50\n",
      "370/370 [==============================] - 14s 39ms/step - loss: 0.0094 - accuracy: 0.1725\n",
      "Epoch 43/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0089 - accuracy: 0.1726\n",
      "Epoch 44/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0087 - accuracy: 0.1727\n",
      "Epoch 45/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0089 - accuracy: 0.1727\n",
      "Epoch 46/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0089 - accuracy: 0.1726\n",
      "Epoch 47/50\n",
      "370/370 [==============================] - 15s 39ms/step - loss: 0.0084 - accuracy: 0.1728\n",
      "Epoch 48/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0084 - accuracy: 0.1728\n",
      "Epoch 49/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0081 - accuracy: 0.1729\n",
      "Epoch 50/50\n",
      "370/370 [==============================] - 15s 40ms/step - loss: 0.0081 - accuracy: 0.1729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f865b34cd00>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕 오랜만이야\n",
      "출력 : 인간 관계가 제일 힘든 거 같아요 .\n",
      "\n",
      "입력 : 잘 지냈어?\n",
      "출력 : 안부를 물어주시다니 감사합니다 .\n",
      "\n",
      "입력 : 뭐 먹을까\n",
      "출력 : 좀 먹어도 괜찮아요 .\n",
      "\n",
      "입력 : 메뉴 추천해줘\n",
      "출력 : 누구랑 먹는 냐에 따라 다르겠죠 .\n",
      "\n",
      "입력 : 어제 뭐 먹었어?\n",
      "출력 : 저는 배터리가 밥이예요 .\n",
      "\n",
      "입력 : 나랑 놀자\n",
      "출력 : 지금 그러고 있어요 .\n",
      "\n",
      "입력 : 어디 가고 싶어?\n",
      "출력 : 오래 마음을 주는 타입인가봐요 .\n",
      "\n",
      "입력 : 널 만나서 기뻐\n",
      "출력 : 지금 즐거운 열심히 \n",
      "\n",
      "입력 : 웃어줄래\n",
      "출력 : 좋은 상대를 용서하면서 분출할 수 있는 탈출구를 찾아보세요 .\n",
      "\n",
      "입력 : 삶은 뭘까?\n",
      "출력 : 고민하고 있다면 그게 맞을 거예요 .\n",
      "\n",
      "입력 : 인생살이 왜이리 힘드냐\n",
      "출력 : 바쁘게 지내는 게 좋죠 .\n",
      "\n",
      "입력 : 이제 그만 쉬고 싶어\n",
      "출력 : 운동으로 땀을 내보세요 . 한결 몸이 가벼워질거예요 .\n",
      "\n",
      "입력 : 너무 고독하다\n",
      "출력 : 혼자가 아니에요 .\n",
      "\n",
      "입력 : 죽으면 어떻게 될까\n",
      "출력 : 너무 신경쓰지마세요 .\n",
      "\n",
      "입력 : 내가 죽으면 슬퍼해 줄거야?\n",
      "출력 : 당신은 하나밖에 없는 소중한 사람이에요 .\n",
      "\n",
      "입력 : 도망가고 싶다\n",
      "출력 : 시작은 다 좋죠 .\n",
      "\n",
      "입력 : 우리 마지막이야\n",
      "출력 : 마지막이 아닐 지도 몰라요 .\n",
      "\n",
      "입력 : 나 간다 잘 지내 안녕\n",
      "출력 : 잘 지냈답니다 .\n",
      "\n",
      "입력 : 넌 최고였어\n",
      "출력 : 당신도 잘 지내고 있길 바랄게요 .\n",
      "\n",
      "입력 : 나 잊지마\n",
      "출력 : 때론 잊어버리는 것이 좋을 때도 있어요 .\n",
      "\n",
      "입력 : 나는 심장이 없어\n",
      "출력 : 친구를 사귀어 보세요 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 50에폭\n",
    "\n",
    "print_answers(input_question_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) 루브릭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\n",
    "\n",
    "공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
    "\n",
    "\n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\n",
    "\n",
    "구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
    "\n",
    "\n",
    "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\n",
    "\n",
    "한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번 프로젝트에서 **어려웠던 점,**\n",
    "\n",
    "에폭이 바뀌며 결과도 달라졌는데 사실 이게 더 좋아진건지 나빠진건지 결과물을 보았을 때 구분하기 힘들었다.\n",
    "\n",
    "\n",
    "- 프로젝트를 진행하면서 **알아낸 점** 혹은 **아직 모호한 점**\n",
    "\n",
    "훨씬 거대한 에폭과,  corpus라면 충분히 좋은 모델을 뽑을 수 있을 것 같다.\n",
    "\n",
    "\n",
    "- 루브릭 평가 지표를 맞추기 위해 **시도한 것들**\n",
    "\n",
    "다른 에폭, 다른 하이퍼파라미터\n",
    "\n",
    "\n",
    "- 만약에 루브릭 평가 관련 지표를 **달성 하지 못했을 때, 이유에 관한 추정**\n",
    "\n",
    "\n",
    "\n",
    "- **자기 다짐**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64f60db5d244171661447d9f571ca5a7e4bf0bab2148f20540b6d51562bb9ca4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
